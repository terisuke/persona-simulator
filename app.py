"""
Persona Debate Simulator (Terisuke Edition)
Streamlitãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
"""

import streamlit as st
import logging
import json
import pickle
import os
import pandas as pd
import io
import subprocess
import glob
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Optional

# å®šæ•°å®šç¾©
MAX_ACCOUNTS = 100  # ä¸€æ‹¬ç®¡ç†ã«å¯¾å¿œã—ã¦ä¸Šé™ã‚’æ‹¡å¼µ
DEFAULT_POST_LIMIT = 20
TOP_K_RELEVANT_POSTS = 3
RECENT_CONTEXT_MESSAGES = 3
BATCH_SIZE = 10  # ãƒãƒƒãƒå‡¦ç†ã®ã‚µã‚¤ã‚º
UI_MAX_RATE_WAIT_SECONDS = 0  # UIã§ã¯ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¾…ã¡ã‚’å®Ÿæ–½ã—ãªã„

# è‡ªä½œãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
from utils.grok_api import GrokAPI
from utils.x_api import XAPIClient
from utils.persona import PersonaManager, PersonaProfile
from utils.similarity import SimilaritySearcher
from utils.debate_ui import DebateUI
from utils.error_handler import APIConnectionError

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="Persona Debate Simulator",
    page_icon="ğŸ’¬",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
CACHE_DIR = ".cache"
os.makedirs(CACHE_DIR, exist_ok=True)


def load_grok_api() -> Optional[GrokAPI]:
    """Grok APIã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ãƒ­ãƒ¼ãƒ‰"""
    try:
        api_key = st.secrets.get("GROK_API_KEY")
        if not api_key:
            st.error("âŒ Grok APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚`.streamlit/secrets.toml`ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            return None
        
        # ã‚ªãƒ—ã‚·ãƒ§ãƒ³: ã‚«ã‚¹ã‚¿ãƒ ãƒ¢ãƒ‡ãƒ«å
        model = st.secrets.get("GROK_MODEL", None)
        
        grok = GrokAPI(api_key, model=model)
        logger.info(f"Grok APIåˆæœŸåŒ–å®Œäº†: ãƒ¢ãƒ‡ãƒ«={grok.model}")
        return grok
    except Exception as e:
        st.error(f"âŒ Grok APIåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
        logger.error(f"Grok APIåˆæœŸåŒ–å¤±æ•—: {str(e)}")
        return None


def load_x_api(use_x_api: bool = True) -> Optional[XAPIClient]:
    """
    X API v2ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ãƒ­ãƒ¼ãƒ‰ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    
    Args:
        use_x_api: X APIã‚’ä½¿ç”¨ã™ã‚‹ã‹ã©ã†ã‹ï¼ˆFalseã®å ´åˆã¯å¸¸ã«Noneã‚’è¿”ã™ï¼‰
    
    Returns:
        XAPIClient ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã¾ãŸã¯ None
    """
    if not use_x_api:
        logger.info("X APIã‚’ä½¿ç”¨ã—ãªã„è¨­å®šã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—")
        return None
    
    try:
        bearer_token = st.secrets.get("X_BEARER_TOKEN")
        if not bearer_token or bearer_token == "your_x_bearer_token_here":
            logger.info("X API Bearer TokenãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰")
            return None
        return XAPIClient(bearer_token)
    except Exception as e:
        logger.warning(f"X APIåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼ï¼ˆç¶šè¡Œå¯èƒ½ï¼‰: {str(e)}")
        return None


def cache_data(key: str, data: any):
    """ãƒ‡ãƒ¼ã‚¿ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜"""
    cache_path = os.path.join(CACHE_DIR, f"{key}.pkl")
    try:
        with open(cache_path, 'wb') as f:
            pickle.dump(data, f)
        logger.info(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜: {key}")
    except Exception as e:
        logger.warning(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜å¤±æ•—: {str(e)}")


def load_cache(key: str) -> Optional[any]:
    """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰"""
    cache_path = os.path.join(CACHE_DIR, f"{key}.pkl")
    if os.path.exists(cache_path):
        try:
            with open(cache_path, 'rb') as f:
                data = pickle.load(f)
            logger.info(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ­ãƒ¼ãƒ‰: {key}")
            return data
        except Exception as e:
            logger.warning(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {str(e)}")
    return None


def delete_cache(key: str):
    """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤"""
    cache_path = os.path.join(CACHE_DIR, f"{key}.pkl")
    if os.path.exists(cache_path):
        try:
            os.remove(cache_path)
            logger.info(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥å‰Šé™¤: {key}")
        except Exception as e:
            logger.warning(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥å‰Šé™¤å¤±æ•—: {str(e)}")


def parse_uploaded_file(uploaded_file) -> List[str]:
    """
    ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãƒªã‚¹ãƒˆã‚’å–å¾—
    
    Args:
        uploaded_file: Streamlitã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        
    Returns:
        ã‚¢ã‚«ã‚¦ãƒ³ãƒˆåã®ãƒªã‚¹ãƒˆ
    """
    try:
        # ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã‚’èª­ã¿è¾¼ã¿
        content = uploaded_file.read()
        
        if uploaded_file.name.endswith('.csv'):
            # CSVãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆ
            df = pd.read_csv(io.StringIO(content.decode('utf-8')))
            
            # usernameåˆ—ã‚’æ¢ã™ï¼ˆå¤§æ–‡å­—å°æ–‡å­—ã‚’åŒºåˆ¥ã—ãªã„ï¼‰
            username_col = None
            for col in df.columns:
                if col.lower() in ['username', 'account', 'user', 'name']:
                    username_col = col
                    break
            
            if username_col is None:
                # æœ€åˆã®åˆ—ã‚’ä½¿ç”¨
                username_col = df.columns[0]
                st.warning(f"usernameåˆ—ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€æœ€åˆã®åˆ— '{username_col}' ã‚’ä½¿ç”¨ã—ã¾ã™")
            
            accounts = df[username_col].astype(str).tolist()
            
        elif uploaded_file.name.endswith('.txt'):
            # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆï¼ˆæ”¹è¡ŒåŒºåˆ‡ã‚Šï¼‰
            content_str = content.decode('utf-8')
            accounts = [line.strip() for line in content_str.split('\n') if line.strip()]
            
        else:
            st.error("ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã§ã™ã€‚CSVã¾ãŸã¯TXTãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
            return []
        
        # ã‚¢ã‚«ã‚¦ãƒ³ãƒˆåã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ï¼ˆ@ã‚’é™¤å»ã€ç©ºç™½ã‚’å‰Šé™¤ï¼‰
        cleaned_accounts = []
        for account in accounts:
            if account and account != 'nan':  # pandasã®NaNã‚’é™¤å¤–
                clean_account = str(account).strip().lstrip('@')
                if clean_account:
                    cleaned_accounts.append(clean_account)
        
        # é‡è¤‡ã‚’é™¤å»
        unique_accounts = list(dict.fromkeys(cleaned_accounts))
        
        logger.info(f"ãƒ•ã‚¡ã‚¤ãƒ«è§£æå®Œäº†: {len(unique_accounts)}ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ")
        return unique_accounts
        
    except Exception as e:
        st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«è§£æã‚¨ãƒ©ãƒ¼: {str(e)}")
        logger.error(f"ãƒ•ã‚¡ã‚¤ãƒ«è§£æå¤±æ•—: {str(e)}")
        return []


def check_cache_status(accounts: List[str]) -> Dict[str, str]:
    """
    ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥çŠ¶æ³ã‚’ãƒã‚§ãƒƒã‚¯
    
    Args:
        accounts: ã‚¢ã‚«ã‚¦ãƒ³ãƒˆåã®ãƒªã‚¹ãƒˆ
        
    Returns:
        ã‚¢ã‚«ã‚¦ãƒ³ãƒˆå -> ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã®è¾æ›¸
    """
    status = {}
    
    for account in accounts:
        cache_key = f"posts_{account}"
        session_key = f"session_data_{account}"
        
        # æ—¢å­˜ã®ã‚¨ãƒ©ãƒ¼ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã¯ç¶­æŒ
        existing_status = st.session_state.get('account_status', {}).get(account)
        if existing_status == 'error':
            status[account] = 'error'
            continue
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆæœ€å„ªå…ˆï¼‰
        if session_key in st.session_state:
            status[account] = "cached_session"
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ãƒã‚§ãƒƒã‚¯
        elif os.path.exists(os.path.join(CACHE_DIR, f"{cache_key}.pkl")):
            status[account] = "cached_file"
        else:
            status[account] = "pending"
    
    return status


def update_account_status(account: str, status: str):
    """
    ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’åŸå­çš„ã«æ›´æ–°
    
    Args:
        account: ã‚¢ã‚«ã‚¦ãƒ³ãƒˆåï¼ˆ@ä»˜ãã§ã‚‚å¯ï¼‰
        status: ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ï¼ˆ'cached_session', 'cached_file', 'pending', 'error', 'unverified'ï¼‰
    """
    account_clean = account.lstrip('@')
    st.session_state.setdefault('account_status', {})[account_clean] = status


def initialize_session_state():
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’åˆæœŸåŒ–"""
    if 'accounts_list' not in st.session_state:
        st.session_state['accounts_list'] = ['cor_terisuke']  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
    
    if 'batch_processing' not in st.session_state:
        st.session_state['batch_processing'] = False
    
    if 'processing_progress' not in st.session_state:
        st.session_state['processing_progress'] = 0
    
    if 'account_status' not in st.session_state:
        st.session_state['account_status'] = {}
    
    if 'account_page' not in st.session_state:
        st.session_state['account_page'] = 0
    
    if 'batch_processed_count' not in st.session_state:
        st.session_state['batch_processed_count'] = 0

    if 'discovery_in_progress' not in st.session_state:
        st.session_state['discovery_in_progress'] = False

    if 'discovered_source' not in st.session_state:
        st.session_state['discovered_source'] = {}
    
    # X APIä½¿ç”¨å¯å¦ã®åˆæœŸåŒ–ï¼ˆX_BEARER_TOKENãŒè¨­å®šã•ã‚Œã¦ã„ã‚Œã°Trueã€ãªã‘ã‚Œã°Falseï¼‰
    if 'use_x_api' not in st.session_state:
        try:
            bearer_token = st.secrets.get("X_BEARER_TOKEN")
            st.session_state['use_x_api'] = bool(bearer_token and bearer_token != "your_x_bearer_token_here")
        except:
            st.session_state['use_x_api'] = False


def restore_session_from_cache():
    """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’å¾©å…ƒ"""
    try:
        # .cacheãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰åˆ©ç”¨å¯èƒ½ãªã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’æ¤œå‡º
        if os.path.exists(CACHE_DIR):
            cached_accounts = []
            for filename in os.listdir(CACHE_DIR):
                if filename.startswith('posts_') and filename.endswith('.pkl'):
                    account = filename.replace('posts_', '').replace('.pkl', '')
                    cached_accounts.append(account)
            
            # æ—¢å­˜ã®ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãƒªã‚¹ãƒˆã¨ãƒãƒ¼ã‚¸
            existing_accounts = set(st.session_state.get('accounts_list', []))
            new_accounts = [acc for acc in cached_accounts if acc not in existing_accounts]
            
            if new_accounts:
                st.session_state['accounts_list'].extend(new_accounts)
                logger.info(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰{len(new_accounts)}ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’å¾©å…ƒ: {new_accounts}")
                
                # ã‚­ãƒ£ãƒƒã‚·ãƒ¥çŠ¶æ³ã‚’æ›´æ–°
                st.session_state['account_status'] = check_cache_status(st.session_state['accounts_list'])
                
                return True
        
        return False
        
    except Exception as e:
        logger.error(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³å¾©å…ƒã‚¨ãƒ©ãƒ¼: {str(e)}")
        return False


def save_session_state():
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’ä¿å­˜ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰"""
    try:
        # é‡è¦ãªçŠ¶æ…‹ã‚’ãƒ­ã‚°ã«è¨˜éŒ²
        accounts_count = len(st.session_state.get('accounts_list', []))
        cached_count = sum(1 for s in st.session_state.get('account_status', {}).values() 
                          if s in ['cached_session', 'cached_file'])
        
        logger.info(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ä¿å­˜: {accounts_count}ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ, {cached_count}ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ¸ˆã¿")
        
    except Exception as e:
        logger.error(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ä¿å­˜ã‚¨ãƒ©ãƒ¼: {str(e)}")


def ensure_quality_score(
    grok_api: GrokAPI,
    persona_profile: PersonaProfile,
    account_clean: str,
    x_api: Optional[XAPIClient] = None
) -> bool:
    """
    persona_profileãŒquality_scoreã‚’æŒã£ã¦ã„ãªã‘ã‚Œã°è©•ä¾¡ã—ã¦ä»˜ä¸ã™ã‚‹ã€‚

    Returns:
        bool: quality_scoreã‚’è¿½åŠ ã—ãŸå ´åˆã¯True
    """
    if not persona_profile or 'quality_score' in persona_profile:
        return False

    account_info = {
        "handle": account_clean,
        "description": persona_profile.get('background', ''),
        "confidence": persona_profile.get('confidence', 0.8)
    }

    try:
        quality_result = grok_api.check_account_quality(
            account_clean,
            account_info,
            x_api_client=x_api
        )
    except Exception as error:
        logger.warning(f"quality_scoreç®—å‡ºã«å¤±æ•—: @{account_clean} - {error}")
        return False

    if not quality_result:
        return False

    persona_profile['quality_score'] = quality_result['score']
    persona_profile['quality_reasons'] = quality_result.get('reasons', [])
    logger.info(f"ğŸ“Š @{account_clean}: quality_score={quality_result['score']:.2f}ã‚’ä»˜ä¸(UI)")
    return True


def has_generated_posts(posts: List[Dict]) -> bool:
    """ç”Ÿæˆãƒ‡ãƒ¼ã‚¿ï¼ˆsample_/generated_ï¼‰ã‹ã©ã†ã‹ã‚’åˆ¤å®š"""
    if not posts:
        return False
    first_id = posts[0].get('id', '')
    return first_id.startswith('sample_') or first_id.startswith('generated_')


def fetch_and_analyze_posts(
    grok_api: GrokAPI, 
    account: str, 
    use_cache: bool = True,
    x_api: Optional[XAPIClient] = None,
    force_refresh: bool = False
) -> tuple[List[Dict], PersonaProfile]:
    """
    æŠ•ç¨¿ã‚’å–å¾—ã—ã¦ãƒšãƒ«ã‚½ãƒŠã‚’ç”Ÿæˆ
    
    Args:
        grok_api: Grok APIã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        account: ã‚¢ã‚«ã‚¦ãƒ³ãƒˆå
        use_cache: ãƒ•ã‚¡ã‚¤ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ä½¿ç”¨ã™ã‚‹ã‹
        x_api: X APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
        force_refresh: å¼·åˆ¶å†å–å¾—ãƒ•ãƒ©ã‚°
    
    Returns:
        (æŠ•ç¨¿ãƒªã‚¹ãƒˆ, ãƒšãƒ«ã‚½ãƒŠãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«)
    """
    account_clean = account.lstrip('@')
    cache_key = f"posts_{account_clean}"
    session_key = f"session_data_{account_clean}"
    
    # å¼·åˆ¶å†å–å¾—ã§ãªã„å ´åˆã€ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆå„ªå…ˆåº¦æœ€é«˜ï¼‰
    if not force_refresh and session_key in st.session_state:
        st.info(f"ğŸ’¾ ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰@{account}ã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰ï¼ˆå†å–å¾—ä¸è¦ï¼‰")
        data = st.session_state[session_key]
        # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’å³æ™‚åæ˜ 
        update_account_status(account_clean, 'cached_session')
        posts = data.get('posts', [])
        if has_generated_posts(posts):
            st.warning(
                f"âš ï¸ @{account} ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ç”Ÿæˆãƒ‡ãƒ¼ã‚¿ã‚’æ¤œå‡ºã—ã¾ã—ãŸã€‚å®Ÿãƒ‡ãƒ¼ã‚¿ã®ã¿å†å–å¾—ã—ã¾ã™ã€‚"
            )
            del st.session_state[session_key]
            delete_cache(cache_key)
        else:
            persona = data.get('persona', {})
            if ensure_quality_score(grok_api, persona, account_clean, x_api):
                # ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ»ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ›´æ–°ï¼ˆquality_scoreã‚’è¿½åŠ ï¼‰
                data['persona'] = persona
                st.session_state[session_key] = data
                cache_data(cache_key, data)
            return posts, persona
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
    if use_cache and not force_refresh:
        cached = load_cache(cache_key)
        if cached:
            st.info(f"ğŸ“¦ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰@{account}ã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰")
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ã‚‚ä¿å­˜
            st.session_state[session_key] = cached
            # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’å³æ™‚åæ˜ 
            update_account_status(account_clean, 'cached_file')
            posts = cached.get('posts', [])
            if has_generated_posts(posts):
                st.warning(
                    f"âš ï¸ @{account}: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ç”Ÿæˆãƒ‡ãƒ¼ã‚¿ãŒå«ã¾ã‚Œã¦ã„ã‚‹ãŸã‚å‰Šé™¤ã—å†å–å¾—ã—ã¾ã™ã€‚"
                )
                delete_cache(cache_key)
                del st.session_state[session_key]
            else:
                persona = cached.get('persona', {})
                if ensure_quality_score(grok_api, persona, account_clean, x_api):
                    cached['persona'] = persona
                    st.session_state[session_key] = cached
                    cache_data(cache_key, cached)
                return posts, persona
    
    # æŠ•ç¨¿å–å¾—
    with st.spinner(f"ğŸ“¡ @{account}ã®æŠ•ç¨¿ã‚’å–å¾—ä¸­..."):
        try:
            posts = grok_api.fetch_posts(
                account, 
                limit=DEFAULT_POST_LIMIT, 
                since_date="2024-01-01",
                x_api_client=x_api,
                max_rate_wait_seconds=UI_MAX_RATE_WAIT_SECONDS if x_api else 900,
                allow_generated=False
            )
        except APIConnectionError as err:
            st.warning(
                f"âš ï¸ @{account} ã®æŠ•ç¨¿å–å¾—ãŒãƒ¬ãƒ¼ãƒˆåˆ¶é™ã®ãŸã‚ä¸­æ–­ã•ã‚Œã¾ã—ãŸã€‚\n"
                "ğŸ‘‰ ãƒãƒƒãƒç”Ÿæˆ(ingest_accounts.py)ã‚’å†å®Ÿè¡Œã—ã€15åˆ†å¾Œã«å†è©¦è¡Œãã ã•ã„ã€‚\n"
                "è©³ã—ãã¯ README ã®ã€ä¸€æ‹¬ç®¡ç†ãƒ¢ãƒ¼ãƒ‰ã€ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚"
            )
            logger.warning(f"UIãƒ¬ãƒ¼ãƒˆåˆ¶é™: @{account} - {err}")
            update_account_status(account_clean, 'error')
            return [], {}
    
    if not posts:
        st.warning(f"âš ï¸ @{account}ã®æŠ•ç¨¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
        # ã‚¨ãƒ©ãƒ¼ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’åæ˜ 
        update_account_status(account_clean, 'error')
        return [], {}
    
    # å–å¾—æ–¹æ³•ã‚’åˆ¤å®šã—ã¦è¡¨ç¤º
    if has_generated_posts(posts):
        st.warning(
            "âš ï¸ ç”Ÿæˆãƒ‡ãƒ¼ã‚¿ã‚’æ¤œå‡ºã—ãŸãŸã‚ã€ã“ã®ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã¯è­°è«–ã‹ã‚‰é™¤å¤–ã—ã¾ã™ã€‚\n"
            "ğŸ‘‰ ingest_accounts.py ã‚’ä½¿ç”¨ã—ã¦å®Ÿãƒ‡ãƒ¼ã‚¿ã‚’å†å–å¾—ã—ã¦ãã ã•ã„ã€‚"
        )
        update_account_status(account_clean, 'unverified')
        delete_cache(cache_key)
        return [], {}

    source = "unknown"
    if posts[0]['id'].startswith('web_search_'):
        st.success(f"âœ… {len(posts)}ä»¶ã®å®ŸæŠ•ç¨¿ã‚’å–å¾—ï¼ˆğŸŒ Grok Web Searchï¼‰")
        source = "web_search"
    else:
        st.success(f"âœ… {len(posts)}ä»¶ã®å®ŸæŠ•ç¨¿ã‚’å–å¾—ï¼ˆğŸ”‘ X API v2ï¼‰")
        source = "twitter"
    
    # ãƒšãƒ«ã‚½ãƒŠç”Ÿæˆï¼ˆãƒãƒ«ãƒãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ å¯¾å¿œï¼‰
    with st.spinner(f"ğŸ§  @{account}ã®ãƒšãƒ«ã‚½ãƒŠã‚’ç”Ÿæˆä¸­..."):
        # Webæ¤œç´¢ã§æƒ…å ±ã‚’å¼·åŒ–ã™ã‚‹ã‹ç¢ºèª
        enable_web = st.session_state.get('enable_web_enrichment', True)
        
        if enable_web:
            st.info("ğŸŒ Webæ¤œç´¢ã§ä»–ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã®æƒ…å ±ã‚’åé›†ä¸­...")
        
        persona_profile = grok_api.generate_persona_profile(
            posts, 
            account=account,
            enable_web_enrichment=enable_web
        )
    
    if persona_profile:
        enrichment_note = "ï¼ˆãƒãƒ«ãƒãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ åˆ†æï¼‰" if enable_web else ""
        st.success(f"âœ… ãƒšãƒ«ã‚½ãƒŠç”Ÿæˆå®Œäº†{enrichment_note}: {persona_profile.get('name', account)}")
        ensure_quality_score(grok_api, persona_profile, account_clean, x_api)
    else:
        st.warning(
            "âš ï¸ ãƒšãƒ«ã‚½ãƒŠã¯æœªç¢ºå®šã§ã™ï¼ˆå®Ÿãƒ‡ãƒ¼ã‚¿ä¸è¶³ã¾ãŸã¯è§£æå¤±æ•—ï¼‰ã€‚\n"
            "ğŸ‘‰ ã¾ãšã¯ CLI ã®ãƒãƒƒãƒå–å¾—ã§å®ŸæŠ•ç¨¿ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç”Ÿæˆã‚’è¡Œã£ã¦ãã ã•ã„ã€‚"
        )
        update_account_status(account_clean, 'unverified')
    
    # ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
    data = {
        'posts': posts,
        'persona': persona_profile or {},
        'fetched_at': datetime.now().isoformat(),
        'source': source
    }
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜
    cache_data(cache_key, data)
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ã‚‚ä¿å­˜ï¼ˆè‡ªå‹•å†å®Ÿè¡Œæ™‚ã«å†å–å¾—ã‚’é˜²ãï¼‰
    st.session_state[session_key] = data
    # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’åæ˜ ï¼ˆæœªç¢ºå®šã®å ´åˆã¯ unverifiedï¼‰
    status = 'cached_session' if persona_profile else 'unverified'
    update_account_status(account_clean, status)
    
    return posts, persona_profile


def get_agent_settings():
    """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ©Ÿèƒ½ã®è¨­å®šã‚’å–å¾—"""
    use_history = st.session_state.get('enable_history', False)
    use_web_search = st.session_state.get('enable_web_search', False)
    enable_web_enrichment = st.session_state.get('enable_web_enrichment', True)
    return use_history, use_web_search, enable_web_enrichment


def build_previous_context(debate_ui) -> str:
    """ç›´è¿‘ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰æ–‡è„ˆã‚’æ§‹ç¯‰"""
    return "\n".join([
        f"@{m.account}: {m.content}"
        for m in debate_ui.get_messages()[-RECENT_CONTEXT_MESSAGES:]
    ])


def main():
    """ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³"""
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
    initialize_session_state()
    if 'grok_history_summary' not in st.session_state:
        st.session_state['grok_history_summary'] = "ä¼šè©±å±¥æ­´ãªã—"
    
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’å¾©å…ƒï¼ˆåˆå›ã®ã¿ï¼‰
    if 'session_restored' not in st.session_state:
        if restore_session_from_cache():
            st.info("ğŸ’¾ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ã‚¢ã‚«ã‚¦ãƒ³ãƒˆæƒ…å ±ã‚’å¾©å…ƒã—ã¾ã—ãŸ")
        st.session_state['session_restored'] = True
    
    # ã‚¿ã‚¤ãƒˆãƒ«
    st.title("ğŸ’¬ Persona Debate Simulator")
    st.markdown("**AI Agent Edition** - Xã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‹ã‚‰ãƒšãƒ«ã‚½ãƒŠã‚’ç”Ÿæˆã—ã€è­°è«–ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã—ã¾ã™")
    
    # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ©Ÿèƒ½èª¬æ˜
    st.markdown("""
    <div style="background-color: #f0f2f6; padding: 10px; border-radius: 5px; margin-bottom: 20px;">
    ğŸ¤– <b>AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ</b> | ğŸŒ ãƒãƒ«ãƒãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ åˆ†æ | ğŸ’¬ ä¼šè©±å±¥æ­´ä¿æŒ
    </div>
    """, unsafe_allow_html=True)
    
    # é€²æ—ã‚µãƒãƒªè¡¨ç¤ºï¼ˆãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢ï¼‰
    accounts = st.session_state.get('accounts_list', [])
    if accounts:
        status = st.session_state.get('account_status', {})
        cached_count = sum(1 for s in status.values() if s in ['cached_session', 'cached_file'])
        pending_count = sum(1 for s in status.values() if s == 'pending')
        error_count = sum(1 for s in status.values() if s == 'error')
        
        # é€²æ—ã‚µãƒãƒªã‚«ãƒ¼ãƒ‰
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric(
                "ç·ã‚¢ã‚«ã‚¦ãƒ³ãƒˆæ•°", 
                len(accounts),
                help="ç™»éŒ²ã•ã‚Œã¦ã„ã‚‹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®ç·æ•°"
            )
        
        with col2:
            st.metric(
                "ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ¸ˆã¿", 
                cached_count,
                delta=f"{cached_count/len(accounts)*100:.1f}%" if accounts else "0%",
                help="ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—æ¸ˆã¿ã®ã‚¢ã‚«ã‚¦ãƒ³ãƒˆæ•°"
            )
        
        with col3:
            st.metric(
                "å–å¾—å¾…ã¡", 
                pending_count,
                delta=f"{pending_count/len(accounts)*100:.1f}%" if accounts else "0%",
                help="ã¾ã ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¦ã„ãªã„ã‚¢ã‚«ã‚¦ãƒ³ãƒˆæ•°"
            )
        
        with col4:
            st.metric(
                "ã‚¨ãƒ©ãƒ¼", 
                error_count,
                delta=f"{error_count/len(accounts)*100:.1f}%" if accounts else "0%",
                help="ãƒ‡ãƒ¼ã‚¿å–å¾—ã«å¤±æ•—ã—ãŸã‚¢ã‚«ã‚¦ãƒ³ãƒˆæ•°"
            )
        
        # é€²æ—ãƒãƒ¼
        if accounts:
            progress = cached_count / len(accounts)
            st.progress(progress, text=f"ãƒ‡ãƒ¼ã‚¿å–å¾—é€²æ—: {cached_count}/{len(accounts)} ({progress*100:.1f}%)")
        
        st.markdown("---")
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    with st.sidebar:
        st.header("âš™ï¸ è¨­å®š")
        
        # APIã‚­ãƒ¼ãƒã‚§ãƒƒã‚¯
        grok_api = load_grok_api()
        if not grok_api:
            st.stop()
        
        st.success("âœ… Grok APIæ¥ç¶šOK")
        
        # X API v2ãƒã‚§ãƒƒã‚¯ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        # æ³¨æ„: ãƒˆã‚°ãƒ«ã¯å¾Œã§è¡¨ç¤ºã•ã‚Œã‚‹ãŒã€ã“ã“ã§ã¯ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’å‚ç…§
        use_x_api_flag = st.session_state.get('use_x_api', True)
        x_api = load_x_api(use_x_api=use_x_api_flag)
        if x_api:
            st.success("âœ… X API v2æ¥ç¶šOKï¼ˆå®ŸæŠ•ç¨¿å–å¾—ï¼‰")
        elif use_x_api_flag:
            st.info("â„¹ï¸ X APIæœªè¨­å®šï¼ˆGrok Web Searchã‚’ä½¿ç”¨ï¼‰")
        else:
            st.info("â„¹ï¸ X APIã¯ç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ã¾ã™ï¼ˆGrok Web Searchã‚’ä½¿ç”¨ï¼‰")
        
        # ã‚¢ã‚«ã‚¦ãƒ³ãƒˆç®¡ç†ï¼ˆä¸€æ‹¬ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¯¾å¿œï¼‰
        st.subheader("ğŸ“ Xã‚¢ã‚«ã‚¦ãƒ³ãƒˆç®¡ç†")
        
        # ä¸€æ‹¬ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚»ã‚¯ã‚·ãƒ§ãƒ³
        st.markdown("**ğŸ“ ä¸€æ‹¬ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰**")
        uploaded_file = st.file_uploader(
            "CSVã¾ãŸã¯TXTãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
            type=['csv', 'txt'],
            help="CSV: usernameåˆ—ã‚’å«ã‚€ãƒ•ã‚¡ã‚¤ãƒ«\nTXT: æ”¹è¡ŒåŒºåˆ‡ã‚Šã§ã‚¢ã‚«ã‚¦ãƒ³ãƒˆåã‚’è¨˜è¼‰"
        )
        
        if uploaded_file is not None:
            if st.button("ğŸ“¥ ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’èª­ã¿è¾¼ã¿", type="primary"):
                accounts_from_file = parse_uploaded_file(uploaded_file)
                if accounts_from_file:
                    # æ—¢å­˜ã®ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã¨ãƒãƒ¼ã‚¸ï¼ˆé‡è¤‡é™¤å»ï¼‰
                    existing_accounts = set(st.session_state['accounts_list'])
                    new_accounts = [acc for acc in accounts_from_file if acc not in existing_accounts]
                    
                    if new_accounts:
                        st.session_state['accounts_list'].extend(new_accounts)
                        st.success(f"âœ… {len(new_accounts)}ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’è¿½åŠ ã—ã¾ã—ãŸ")
                    else:
                        st.info("æ–°ã—ã„ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                    
                    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥çŠ¶æ³ã‚’æ›´æ–°
                    st.session_state['account_status'] = check_cache_status(st.session_state['accounts_list'])
                    st.rerun()
        
        st.markdown("---")
        
        # ç¾åœ¨ã®ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãƒªã‚¹ãƒˆè¡¨ç¤º
        accounts = st.session_state['accounts_list']
        if accounts:
            # é€²æ—ã‚µãƒãƒªè¡¨ç¤º
            status = st.session_state.get('account_status', {})
            cached_count = sum(1 for s in status.values() if s in ['cached_session', 'cached_file'])
            pending_count = sum(1 for s in status.values() if s == 'pending')
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("ç·ã‚¢ã‚«ã‚¦ãƒ³ãƒˆæ•°", len(accounts))
            with col2:
                st.metric("ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ¸ˆã¿", cached_count)
            with col3:
                st.metric("å–å¾—å¾…ã¡", pending_count)
            
            st.markdown("**ç™»éŒ²æ¸ˆã¿ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ:**")
            
            # ãƒšãƒ¼ã‚¸ãƒ³ã‚°å¯¾å¿œï¼ˆ10ä»¶ãšã¤è¡¨ç¤ºï¼‰
            page_size = 10
            total_pages = (len(accounts) + page_size - 1) // page_size
            current_page = st.session_state.get('account_page', 0)
            
            if total_pages > 1:
                col1, col2, col3 = st.columns([1, 2, 1])
                with col1:
                    if st.button("â—€ï¸", disabled=(current_page == 0)):
                        st.session_state['account_page'] = max(0, current_page - 1)
                        st.rerun()
                with col2:
                    st.caption(f"ãƒšãƒ¼ã‚¸ {current_page + 1} / {total_pages}")
                with col3:
                    if st.button("â–¶ï¸", disabled=(current_page >= total_pages - 1)):
                        st.session_state['account_page'] = min(total_pages - 1, current_page + 1)
                        st.rerun()
            
            # ç¾åœ¨ã®ãƒšãƒ¼ã‚¸ã®ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’è¡¨ç¤º
            start_idx = current_page * page_size
            end_idx = min(start_idx + page_size, len(accounts))
            page_accounts = accounts[start_idx:end_idx]
            
            for i, acc in enumerate(page_accounts):
                actual_idx = start_idx + i
                col1, col2, col3 = st.columns([3, 1, 1])
                
                with col1:
                    # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤º
                    acc_status = status.get(acc, 'pending')
                    if acc_status == 'cached_session':
                        st.text(f"@{acc} âœ…")
                    elif acc_status == 'cached_file':
                        st.text(f"@{acc} ğŸ“¦")
                    else:
                        st.text(f"@{acc} â³")
                
                with col2:
                    if st.button("ğŸ”„", key=f"refresh_{actual_idx}", help=f"@{acc}ã®æŠ•ç¨¿ã‚’å†å–å¾—"):
                        # å€‹åˆ¥ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢
                        session_key = f"session_data_{acc}"
                        if session_key in st.session_state:
                            del st.session_state[session_key]
                        # all_dataã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚‚ã‚¯ãƒªã‚¢ï¼ˆå†æ§‹ç¯‰ãŒå¿…è¦ï¼‰
                        if 'all_data_cache' in st.session_state:
                            del st.session_state['all_data_cache']
                        if 'cached_accounts_key' in st.session_state:
                            del st.session_state['cached_accounts_key']
                        st.success(f"âœ… @{acc}ã®æŠ•ç¨¿ã‚’å†å–å¾—ã—ã¾ã™")
                        st.rerun()
                
                with col3:
                    if st.button("ğŸ—‘ï¸", key=f"delete_{actual_idx}", help=f"@{acc}ã‚’å‰Šé™¤"):
                        st.session_state['accounts_list'].pop(actual_idx)
                        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚‚å‰Šé™¤
                        session_key = f"session_data_{acc}"
                        if session_key in st.session_state:
                            del st.session_state[session_key]
                        # all_dataã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚‚ã‚¯ãƒªã‚¢
                        if 'all_data_cache' in st.session_state:
                            del st.session_state['all_data_cache']
                        if 'cached_accounts_key' in st.session_state:
                            del st.session_state['cached_accounts_key']
                        # ãƒšãƒ¼ã‚¸ã‚’èª¿æ•´
                        if current_page > 0 and len(st.session_state['accounts_list']) <= current_page * page_size:
                            st.session_state['account_page'] = max(0, current_page - 1)
                        st.rerun()
        
        st.markdown("---")
        
        # æ–°è¦ã‚¢ã‚«ã‚¦ãƒ³ãƒˆè¿½åŠ ï¼ˆå€‹åˆ¥ï¼‰
        if len(accounts) < MAX_ACCOUNTS:
            st.markdown("**â• å€‹åˆ¥ã‚¢ã‚«ã‚¦ãƒ³ãƒˆè¿½åŠ :**")
            new_account = st.text_input(
                "ã‚¢ã‚«ã‚¦ãƒ³ãƒˆåã‚’å…¥åŠ›",
                value="",
                key="new_account_input",
                placeholder="ä¾‹: elonmuskï¼ˆ@ãªã—ã§å…¥åŠ›ï¼‰",
                help="ã‚¢ã‚«ã‚¦ãƒ³ãƒˆåã‚’å®Œå…¨ã«å…¥åŠ›ã—ã¦ã‹ã‚‰è¿½åŠ ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯",
                autocomplete="off"
            )
            
            col1, col2 = st.columns([3, 1])
            with col1:
                if st.button("â• ã‚¢ã‚«ã‚¦ãƒ³ãƒˆè¿½åŠ ", type="primary", use_container_width=True):
                    if new_account.strip():
                        clean_account = new_account.strip().lstrip('@')
                        if clean_account not in accounts:
                            st.session_state['accounts_list'].append(clean_account)
                            st.success(f"âœ… @{clean_account}ã‚’è¿½åŠ ã—ã¾ã—ãŸ")
                            st.rerun()
                        else:
                            st.warning(f"âš ï¸ @{clean_account}ã¯æ—¢ã«ç™»éŒ²ã•ã‚Œã¦ã„ã¾ã™")
                    else:
                        st.error("ã‚¢ã‚«ã‚¦ãƒ³ãƒˆåã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
            
            with col2:
                if st.button("ğŸ”„ ãƒªã‚»ãƒƒãƒˆ", use_container_width=True):
                    st.session_state['accounts_list'] = ['cor_terisuke']
                    st.session_state['account_page'] = 0
                    st.success("ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã«ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸ")
                    st.rerun()
        else:
            st.warning(f"âš ï¸ æœ€å¤§{MAX_ACCOUNTS}ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã¾ã§ç™»éŒ²å¯èƒ½ã§ã™")
        
        # accountså¤‰æ•°ã«ä»£å…¥ï¼ˆå¾Œç¶šã®å‡¦ç†ã§ä½¿ç”¨ï¼‰
        accounts = st.session_state['accounts_list']
        
        # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ©Ÿèƒ½è¨­å®š
        st.subheader("ğŸ¤– ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ©Ÿèƒ½")
        
        enable_web_enrichment = st.checkbox(
            "ãƒãƒ«ãƒãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ åˆ†æ", 
            value=True, 
            help="Instagramã€LinkedInã€ãƒ–ãƒ­ã‚°ç­‰ã‚‚æ¤œç´¢ã—ã¦ãƒšãƒ«ã‚½ãƒŠç²¾åº¦ã‚’å‘ä¸Š"
        )
        st.session_state['enable_web_enrichment'] = enable_web_enrichment
        
        enable_history = st.checkbox(
            "ä¼šè©±å±¥æ­´ã‚’ä¿æŒ", 
            value=False, 
            help="è¤‡æ•°å›ã®è­°è«–ã§æ–‡è„ˆã‚’ç¶™ç¶šï¼ˆAIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ©Ÿèƒ½ï¼‰"
        )
        
        enable_web_search = st.checkbox(
            "Webæ¤œç´¢ã‚’æœ‰åŠ¹åŒ–", 
            value=False, 
            help="æœ€æ–°æƒ…å ±ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¤œç´¢ï¼ˆAIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ©Ÿèƒ½ï¼‰"
        )
        
        # ä¼šè©±å±¥æ­´ç®¡ç†
        if enable_history:
            if 'grok_history_summary' in st.session_state:
                st.info(f"ğŸ“ {st.session_state['grok_history_summary']}")
            
            if st.button("ğŸ—‘ï¸ ä¼šè©±å±¥æ­´ã‚’ã‚¯ãƒªã‚¢"):
                if grok_api:
                    grok_api.clear_conversation_history()
                    st.session_state['grok_history_summary'] = "ä¼šè©±å±¥æ­´ãªã—"
                    st.success("ä¼šè©±å±¥æ­´ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ")
                    st.rerun()
        
        st.divider()
        
        # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆStage3æº–å‚™ï¼‰
        st.subheader("ğŸŒ ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ãƒ•ã‚£ãƒ«ã‚¿")
        source_filter = st.multiselect(
            "è¡¨ç¤ºã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹",
            options=["å…¨ã¦", "Twitter", "Web", "Sample", "Keyword", "Random", "Diversity"],
            default=["å…¨ã¦"],
            help="ãƒ‡ãƒ¼ã‚¿å–å¾—å…ƒã§ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆTwitter=ğŸ”‘ X API, Web=ğŸŒ Grok æ¤œç´¢, Sample=ğŸ“ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯, Diversity=å¤šæ§˜æ€§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼‰"
        )
        st.session_state["source_filter"] = source_filter
        
        # åé›†ï¼ˆStage2.5ï¼‰
        st.subheader("ğŸ” ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§åé›†")
        discover_keyword = st.text_input(
            "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰",
            value="AI engineer",
            help="ä¾‹: AI engineer, LLM researcher, startup founder ãªã©",
            autocomplete="off"
        )
        max_results = st.slider(
            "æœ€å¤§äººæ•°",
            min_value=1,
            max_value=100,
            value=50
        )
        col_dk1, col_dk2 = st.columns([2, 1])
        with col_dk1:
            if st.button("ğŸš€ åé›†é–‹å§‹", use_container_width=True):
                st.session_state['discovery_in_progress'] = True
                st.session_state['discovery_mode'] = 'keyword'
                st.rerun()
        with col_dk2:
            dry_run = st.toggle("ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³", value=False, help="Grokæœªè¨­å®šã§ã‚‚å›ºå®šãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã§å‹•ä½œç¢ºèª")

        st.caption("ğŸ§® å¤šæ§˜æ€§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ï¼‰")
        use_diversity_sampling = st.checkbox(
            "å¤šæ§˜æ€§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚’å®Ÿè¡Œã™ã‚‹",
            key="ui_use_diversity_sampling",
            help="X APIã¨Grok Web Searchã‚’çµ„ã¿åˆã‚ã›ã¦å¤šæ§˜æ€§ã‚’æ‹…ä¿ã—ãŸå€™è£œãƒªã‚¹ãƒˆã‚’åé›†ã—ã¾ã™"
        )
        if use_diversity_sampling:
            sampling_method = st.selectbox(
                "ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ‰‹æ³•",
                options=["stratified", "quota", "random"],
                format_func=lambda x: {
                    "stratified": "å±¤åŒ–ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°",
                    "quota": "ã‚¯ã‚©ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°",
                    "random": "ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°"
                }[x],
                key="ui_diversity_sampling_method"
            )
            prefer_x_api_toggle = st.toggle(
                "X APIã‚’å„ªå…ˆã™ã‚‹",
                value=st.session_state.get('use_x_api', True),
                key="ui_diversity_prefer_x_api"
            )
            fallback_toggle = st.toggle(
                "Grok Web Searchã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã™ã‚‹",
                value=True,
                key="ui_diversity_fallback"
            )
            if st.button("ğŸ§® å¤šæ§˜æ€§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚’é–‹å§‹", use_container_width=True):
                st.session_state['discovery_in_progress'] = True
                st.session_state['discovery_mode'] = 'diversity'
                st.session_state['diversity_params'] = {
                    'sampling_method': sampling_method,
                    'prefer_x_api': prefer_x_api_toggle,
                    'fallback_to_grok': fallback_toggle,
                    'dry_run': dry_run
                }
                st.rerun()

        st.caption("ğŸ² ãƒ©ãƒ³ãƒ€ãƒ åé›†ï¼ˆãƒ—ãƒªã‚»ãƒƒãƒˆã‚¯ã‚¨ãƒªï¼‰")
        if st.button("ğŸ² ãƒ©ãƒ³ãƒ€ãƒ åé›†ã‚’é–‹å§‹", use_container_width=True):
            st.session_state['discovery_in_progress'] = True
            st.session_state['discovery_mode'] = 'random'
            st.rerun()

        # åé›†ä¸­ã®å‡¦ç†
        if st.session_state.get('discovery_in_progress', False):
            st.info("ğŸ”„ å€™è£œã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’åé›†ä¸­â€¦ å°‘ã—ãŠå¾…ã¡ãã ã•ã„")
            try:
                discover_dir = Path(".cache/discover_results")
                discover_dir.mkdir(parents=True, exist_ok=True)

                mode = st.session_state.get('discovery_mode', 'keyword')

                if mode == 'diversity':
                    params = st.session_state.get('diversity_params', {}) or {}
                    sampling_method = params.get('sampling_method', 'stratified')
                    prefer_x_api_flag = params.get('prefer_x_api', True)
                    fallback_flag = params.get('fallback_to_grok', True)
                    cmd = [
                        "python", "ingest_accounts.py", "--diversity-sampling",
                        "--max-results", str(max_results)
                    ]
                    if sampling_method:
                        cmd.extend(["--sampling-method", sampling_method])
                    if not prefer_x_api_flag:
                        cmd.append("--no-prefer-x-api")
                    if not fallback_flag:
                        cmd.append("--no-fallback-grok")
                    if params.get('dry_run'):
                        cmd.append("--dry-run")
                    if not st.session_state.get('use_x_api', True):
                        cmd.append("--no-x-api")
                    subprocess.run(cmd, check=True)
                    pattern_csv = str(discover_dir / f"diversity_{sampling_method}_hybrid_accounts_*.csv")
                    pattern_txt = str(discover_dir / f"diversity_{sampling_method}_hybrid_accounts_*.txt")
                    discovered_kind = "diversity_hybrid"
                elif mode == 'random':
                    cmd = [
                        "python", "ingest_accounts.py", "--discover-random",
                        "--max-results", str(max_results)
                    ]
                    if dry_run:
                        cmd.append("--dry-run")
                    if not st.session_state.get('use_x_api', True):
                        cmd.append("--no-x-api")
                    subprocess.run(cmd, check=True)
                    pattern_csv = str(discover_dir / "random_accounts_*.csv")
                    pattern_txt = str(discover_dir / "random_accounts_*.txt")
                    discovered_kind = "grok_random"
                else:
                    cmd = [
                        "python", "ingest_accounts.py", "--discover-keyword", discover_keyword,
                        "--max-results", str(max_results)
                    ]
                    if dry_run:
                        cmd.append("--dry-run")
                    if not st.session_state.get('use_x_api', True):
                        cmd.append("--no-x-api")
                    subprocess.run(cmd, check=True)
                    pattern_csv = str(discover_dir / "keyword_*.csv")
                    pattern_txt = str(discover_dir / "keyword_*.txt")
                    discovered_kind = "grok_keyword"

                # æœ€æ–°ã®çµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
                candidates = []
                files = sorted(glob.glob(pattern_csv) + glob.glob(pattern_txt), key=lambda p: Path(p).stat().st_mtime, reverse=True)
                latest = files[0] if files else None
                if latest:
                    if latest.endswith('.csv'):
                        try:
                            df = pd.read_csv(latest)
                            # handle åˆ—ãŒåŸºæœ¬ã€ãªã‘ã‚Œã° username/account/name ã‚’ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                            handle_col = None
                            for col in df.columns:
                                if str(col).lower() in ["handle", "username", "account", "name"]:
                                    handle_col = col
                                    break
                            if handle_col is not None:
                                candidates = [str(h).strip().lstrip('@') for h in df[handle_col].tolist() if str(h).strip()]
                            # ç™ºè¦‹å…ƒã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«è¨˜éŒ²ï¼ˆStage1ãŒæœªå®Ÿè¡Œã§ã‚‚UIè¡¨ç¤ºç”¨ï¼‰
                            for h in candidates:
                                st.session_state['discovered_source'][h] = discovered_kind
                        except Exception as e:
                            st.warning(f"çµæœCSVã®èª­è¾¼ã«å¤±æ•—: {e}")
                    else:
                        try:
                            with open(latest, 'r', encoding='utf-8') as f:
                                lines = [l.strip() for l in f if l.strip() and not l.strip().startswith('#')]
                                candidates = [l.lstrip('@') for l in lines]
                            for h in candidates:
                                st.session_state['discovered_source'][h] = discovered_kind
                        except Exception as e:
                            st.warning(f"çµæœTXTã®èª­è¾¼ã«å¤±æ•—: {e}")

                # æ—¢å­˜ã«ãƒãƒ¼ã‚¸ï¼ˆä¸Šé™ãƒã‚§ãƒƒã‚¯ï¼‰
                if candidates:
                    existing_list = st.session_state.get('accounts_list', [])
                    existing = set(existing_list)
                    new_unique = [c for c in candidates if c not in existing]
                    if new_unique:
                        available = max(0, MAX_ACCOUNTS - len(existing_list))
                        if available <= 0:
                            st.warning(f"æœ€å¤§ {MAX_ACCOUNTS} ä»¶ã«é”ã—ã¦ã„ã¾ã™ã€‚æ–°è¦è¿½åŠ ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
                            to_add = []
                        else:
                            to_add = new_unique[:available]
                            dropped = max(0, len(new_unique) - available)
                            if dropped > 0:
                                st.warning(f"{dropped} ä»¶ã¯ä¸Šé™è¶…éã®ãŸã‚è¿½åŠ ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
                            st.session_state['accounts_list'].extend(to_add)
                            # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æ›´æ–°
                            st.session_state['account_status'] = check_cache_status(st.session_state['accounts_list'])
                        if to_add:
                            st.success(f"âœ… æ–°è¦ {len(to_add)} ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’è¿½åŠ ã—ã¾ã—ãŸ")
                    else:
                        st.info("æ–°è¦è¿½åŠ ã¯ã‚ã‚Šã¾ã›ã‚“ï¼ˆé‡è¤‡ï¼‰")
                    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã¨Stage1é€ä»˜
                    st.download_button(
                        label="ğŸ“¥ åé›†ãƒªã‚¹ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                        data=open(latest, 'rb').read(),
                        file_name=Path(latest).name
                    )
                    if st.button("ğŸ“¦ Stage1(ingest_accounts.py) ã«é€ã‚‹", use_container_width=True):
                        try:
                            cmd = ["python", "ingest_accounts.py", latest]
                            if not st.session_state.get('use_x_api', True):
                                cmd.append("--no-x-api")
                            subprocess.run(cmd, check=True)
                            st.success("Stage1 ãƒãƒƒãƒã‚’é–‹å§‹ã—ã¾ã—ãŸã€‚å®Œäº†å¾Œã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒåæ˜ ã•ã‚Œã¾ã™ã€‚")
                        except Exception as e:
                            st.error(f"Stage1 å®Ÿè¡Œã«å¤±æ•—: {e}")
                else:
                    st.warning("å€™è£œãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")

            except subprocess.CalledProcessError as e:
                st.error(f"åé›†ã‚³ãƒãƒ³ãƒ‰ãŒå¤±æ•—ã—ã¾ã—ãŸ: {e}")
            except Exception as e:
                st.error(f"åé›†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
            finally:
                st.session_state['discovery_in_progress'] = False
                st.session_state.pop('discovery_mode', None)
                st.session_state.pop('diversity_params', None)
                st.rerun()

        # X APIä½¿ç”¨ãƒˆã‚°ãƒ«
        st.subheader("ğŸ”‘ X APIè¨­å®š")
        use_x_api = st.toggle(
            "X APIã‚’ä½¿ç”¨ã™ã‚‹",
            value=st.session_state.get('use_x_api', True),
            help="X APIã‚’ç„¡åŠ¹åŒ–ã™ã‚‹ã¨ã€Grok Web Searchã®ã¿ã§æŠ•ç¨¿ã‚’å–å¾—ã—ã¾ã™ã€‚quality_scoreã¯æš«å®šå€¤ã«ãªã‚Šã¾ã™ã€‚"
        )
        st.session_state['use_x_api'] = use_x_api
        
        if not use_x_api:
            mode_val = st.secrets.get("MODE", "dev")
            is_operational_mode = str(mode_val).lower() in {"prod", "staging"}
            if is_operational_mode:
                st.warning("âš ï¸ é‹ç”¨ãƒ¢ãƒ¼ãƒ‰ã§X APIã‚’ç„¡åŠ¹åŒ–ã—ã¦ã„ã¾ã™ã€‚quality_scoreã¯æš«å®šå€¤ã«ãªã‚Šã¾ã™ã€‚")
            else:
                st.info("â„¹ï¸ X APIãŒç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ã¾ã™ã€‚Grok Web Searchã®ã¿ã§å–å¾—ã—ã¾ã™ã€‚")

        # ãƒãƒƒãƒå‡¦ç†ã‚»ã‚¯ã‚·ãƒ§ãƒ³
        st.subheader("âš¡ ãƒãƒƒãƒå‡¦ç†")
        
        # ä¸è¶³åˆ†ã‚’å–å¾—ãƒœã‚¿ãƒ³
        if accounts:
            pending_accounts = [acc for acc, status in st.session_state.get('account_status', {}).items() 
                              if status == 'pending']
            
            if pending_accounts:
                st.info(f"â³ {len(pending_accounts)}ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®å–å¾—å¾…ã¡ãŒã‚ã‚Šã¾ã™")
                
                if st.button("ğŸš€ ä¸è¶³åˆ†ã‚’å–å¾—", type="primary", use_container_width=True):
                    st.session_state['batch_processing'] = True
                    st.session_state['processing_progress'] = 0
                    st.rerun()
            else:
                st.success("âœ… å…¨ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®ãƒ‡ãƒ¼ã‚¿ãŒæƒã£ã¦ã„ã¾ã™")
        
        # ãƒãƒƒãƒå‡¦ç†ä¸­ã®é€²æ—è¡¨ç¤º
        if st.session_state.get('batch_processing', False):
            st.progress(st.session_state.get('processing_progress', 0))
            st.info("ğŸ”„ ãƒãƒƒãƒå‡¦ç†ä¸­...")
        
        st.divider()
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥åˆ¶å¾¡
        st.subheader("ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ç®¡ç†")
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚Œã¦ã„ã‚‹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’è¡¨ç¤º
        cached_accounts = [k.replace('session_data_', '') for k in st.session_state.keys() if k.startswith('session_data_')]
        if cached_accounts:
            st.caption(f"ğŸ“Œ ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ¸ˆã¿: {', '.join(['@' + a for a in cached_accounts])}")
        else:
            st.caption("ğŸ“Œ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãªã—")
        
        use_cache = st.checkbox("ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ä½¿ç”¨", value=True, help="ä»¥å‰å–å¾—ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’å†åˆ©ç”¨")
        
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ”„ å…¨ã¦å†å–å¾—", use_container_width=True, help="å…¨ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®æŠ•ç¨¿ã‚’å†å–å¾—"):
                # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢
                keys_to_clear = [k for k in st.session_state.keys() if k.startswith('session_data_')]
                for key in keys_to_clear:
                    del st.session_state[key]
                # all_dataã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚‚ã‚¯ãƒªã‚¢
                if 'all_data_cache' in st.session_state:
                    del st.session_state['all_data_cache']
                if 'cached_accounts_key' in st.session_state:
                    del st.session_state['cached_accounts_key']
                st.success("âœ… å…¨ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã™")
                st.rerun()
        
        with col2:
            if st.button("ğŸ—‘ï¸ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢", use_container_width=True, help="ãƒ•ã‚¡ã‚¤ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’å‰Šé™¤"):
                import shutil
                if os.path.exists(CACHE_DIR):
                    shutil.rmtree(CACHE_DIR)
                    os.makedirs(CACHE_DIR)
                # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚‚ã‚¯ãƒªã‚¢
                keys_to_clear = [k for k in st.session_state.keys() if k.startswith('session_data_')]
                for key in keys_to_clear:
                    del st.session_state[key]
                # all_dataã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚‚ã‚¯ãƒªã‚¢
                if 'all_data_cache' in st.session_state:
                    del st.session_state['all_data_cache']
                if 'cached_accounts_key' in st.session_state:
                    del st.session_state['cached_accounts_key']
                st.success("âœ… ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ")
                st.rerun()

        # ã‚¨ãƒ©ãƒ¼ä¸€è¦§ï¼ˆ429ç­‰ã®å¤±æ•—ã‚’å¯è¦–åŒ–ï¼‰
        st.markdown("---")
        st.subheader("âŒ ã‚¨ãƒ©ãƒ¼ä¸€è¦§")
        error_accounts = [acc for acc, s in st.session_state.get('account_status', {}).items() if s == 'error']
        if error_accounts:
            err_df = pd.DataFrame({"ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ": [f"@{a}" for a in error_accounts]})
            st.dataframe(err_df, width='content', hide_index=True)
            if st.button("ğŸ” ã‚¨ãƒ©ãƒ¼ã‚’å†è©¦è¡Œ", use_container_width=True):
                # ã‚¨ãƒ©ãƒ¼çŠ¶æ…‹ã‚’pendingã¸æˆ»ã—ã€æ¬¡ã®ãƒãƒƒãƒã§å†å–å¾—
                for a in error_accounts:
                    update_account_status(a, 'pending')
                # ã‚µãƒãƒªãƒ»ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å³æ™‚æ›´æ–°
                st.session_state['account_status'] = check_cache_status(st.session_state.get('accounts_list', []))
                st.session_state['batch_processing'] = True
                st.session_state['processing_progress'] = 0
                st.success("å†è©¦è¡Œã‚’é–‹å§‹ã—ã¾ã—ãŸ")
                st.rerun()
        else:
            st.caption("ç¾åœ¨ã‚¨ãƒ©ãƒ¼ã¯ã‚ã‚Šã¾ã›ã‚“")
        
        # KPIã‚«ãƒ¼ãƒ‰ï¼ˆã‚µã‚¤ãƒ‰ãƒãƒ¼ä¸‹éƒ¨ï¼‰
        st.markdown("---")
        st.subheader("ğŸ“Š å“è³ªKPI")
        
        # ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã‹ã‚‰KPIã‚’è¨ˆç®—
        accounts_list = st.session_state.get('accounts_list', [])
        if accounts_list:
            # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹åˆ¥ã‚«ã‚¦ãƒ³ãƒˆ
            twitter_count = 0
            web_search_count = 0
            generated_count = 0
            unverified_count = 0
            quality_scores = []
            
            for account in accounts_list:
                account_clean = account.lstrip('@')
                session_key = f"session_data_{account_clean}"
                
                if session_key in st.session_state:
                    data = st.session_state[session_key]
                    source = data.get('source', 'unknown')
                    
                    if source == 'twitter':
                        twitter_count += 1
                    elif source == 'web_search':
                        web_search_count += 1
                    elif source == 'generated':
                        generated_count += 1
                    
                    # æœªç¢ºå®šãƒã‚§ãƒƒã‚¯
                    persona = data.get('persona', {})
                    if not persona or len(persona) == 0:
                        unverified_count += 1
                    
                    # quality_scoreé›†è¨ˆ
                    if 'quality_score' in persona:
                        quality_scores.append(persona['quality_score'])
                
                # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‹ã‚‰æœªç¢ºå®šã‚’ã‚«ã‚¦ãƒ³ãƒˆ
                status = st.session_state.get('account_status', {}).get(account_clean, 'pending')
                if status == 'unverified':
                    unverified_count += 1
            
            total = len(accounts_list)
            if total > 0:
                real_count = twitter_count + web_search_count
                real_ratio = (real_count / total) * 100
                generated_ratio = (generated_count / total) * 100
                
                # å®Ÿ/ç”Ÿæˆæ¯”
                col1, col2 = st.columns(2)
                with col1:
                    st.metric("å®Ÿãƒ‡ãƒ¼ã‚¿æ¯”ç‡", f"{real_ratio:.1f}%", f"{real_count}/{total}")
                with col2:
                    if generated_ratio > 0:
                        st.metric("ç”Ÿæˆãƒ‡ãƒ¼ã‚¿ç‡", f"{generated_ratio:.1f}%", f"{generated_count}/{total}", delta_color="inverse")
                    else:
                        st.metric("ç”Ÿæˆãƒ‡ãƒ¼ã‚¿ç‡", "0%", "0/0")
                
                # æœªç¢ºå®šæ•°
                st.metric("æœªç¢ºå®šãƒšãƒ«ã‚½ãƒŠ", unverified_count, f"å…¨{total}ä»¶ä¸­")
                
                # å¹³å‡/ä¸­å¤®å€¤quality_score
                if quality_scores:
                    avg_quality = sum(quality_scores) / len(quality_scores)
                    median_quality = sorted(quality_scores)[len(quality_scores) // 2]
                    
                    col1, col2 = st.columns(2)
                    with col1:
                        st.metric("å¹³å‡quality_score", f"{avg_quality:.2f}", f"{len(quality_scores)}ä»¶")
                    with col2:
                        st.metric("ä¸­å¤®å€¤quality_score", f"{median_quality:.2f}", "")
                    
                    # X APIç„¡åŠ¹æ™‚ã®è­¦å‘Š
                    if not st.session_state.get('use_x_api', True):
                        st.warning("âš ï¸ X APIãŒç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€quality_scoreã¯æš«å®šå€¤ã§ã™ã€‚")
                else:
                    st.caption("quality_scoreãƒ‡ãƒ¼ã‚¿ãªã—")
                    # X APIç„¡åŠ¹æ™‚ã®è­¦å‘Š
                    if not st.session_state.get('use_x_api', True):
                        st.warning("âš ï¸ X APIãŒç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€quality_scoreã¯æš«å®šå€¤ã«ãªã‚Šã¾ã™ã€‚")
                
                # é‹ç”¨ãƒ¢ãƒ¼ãƒ‰è­¦å‘Šï¼ˆç”Ÿæˆãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆï¼‰
                mode_val = st.secrets.get("MODE", "dev")
                is_operational = str(mode_val).lower() in {"prod", "staging"}
                
                if is_operational and generated_ratio > 0:
                    st.error(f"âš ï¸ é‹ç”¨ãƒ¢ãƒ¼ãƒ‰ã§ç”Ÿæˆãƒ‡ãƒ¼ã‚¿ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ ({generated_ratio:.1f}%)")
                    st.caption("å®Ÿãƒ‡ãƒ¼ã‚¿å–å¾—ã‚’å†å®Ÿè¡Œã—ã¦ãã ã•ã„")
            else:
                st.caption("ãƒ‡ãƒ¼ã‚¿ãªã—")
        else:
            st.caption("ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãŒç™»éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“")
    
    # ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢
    if not accounts:
        st.info("ğŸ‘ˆ ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰Xã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        return
    
    # ãƒãƒƒãƒå‡¦ç†ã®å®Ÿè¡Œ
    if st.session_state.get('batch_processing', False):
        pending_accounts = [acc for acc, status in st.session_state.get('account_status', {}).items() 
                          if status == 'pending']
        
        if pending_accounts and grok_api:
            # ãƒãƒƒãƒã‚µã‚¤ã‚ºã§åˆ†å‰²ã—ã¦å‡¦ç†
            total_pending = len(pending_accounts)
            processed = st.session_state.get('batch_processed_count', 0)
            
            if processed < total_pending:
                # æ¬¡ã®ãƒãƒƒãƒã‚’å‡¦ç†
                start_idx = processed
                end_idx = min(start_idx + BATCH_SIZE, total_pending)
                current_batch = pending_accounts[start_idx:end_idx]
                
                st.info(f"ğŸ”„ ãƒãƒƒãƒå‡¦ç†ä¸­: {processed + 1}-{end_idx} / {total_pending}")
                
                # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã‚’æ›´æ–°
                progress = (processed + len(current_batch)) / total_pending
                st.session_state['processing_progress'] = progress
                
                # ãƒãƒƒãƒå†…ã®ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’å‡¦ç†
                for i, account in enumerate(current_batch):
                    with st.spinner(f"ğŸ“¡ @{account}ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­... ({i+1}/{len(current_batch)})"):
                        try:
                            posts, persona = fetch_and_analyze_posts(
                                grok_api, 
                                account, 
                                use_cache=True, 
                                x_api=x_api,
                                force_refresh=False
                            )
                            
                            if posts and persona:
                                # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’æ›´æ–°
                                update_account_status(account, 'cached_session')
                                st.success(f"âœ… @{account}ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—å®Œäº†")
                            else:
                                st.warning(f"âš ï¸ @{account}ã®ãƒ‡ãƒ¼ã‚¿å–å¾—ã«å¤±æ•—")
                                update_account_status(account, 'error')
                                
                        except Exception as e:
                            st.error(f"âŒ @{account}ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼: {str(e)}")
                            logger.error(f"ãƒãƒƒãƒå‡¦ç†ã‚¨ãƒ©ãƒ¼ @{account}: {str(e)}")
                            update_account_status(account, 'error')
                
                # å‡¦ç†æ¸ˆã¿ã‚«ã‚¦ãƒ³ãƒˆã‚’æ›´æ–°
                st.session_state['batch_processed_count'] = end_idx
                
                # å…¨ã¦å®Œäº†ã—ãŸã‹ãƒã‚§ãƒƒã‚¯
                if end_idx >= total_pending:
                    st.session_state['batch_processing'] = False
                    st.session_state['batch_processed_count'] = 0
                    st.success("ğŸ‰ ãƒãƒƒãƒå‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                    st.rerun()
                else:
                    # æ¬¡ã®ãƒãƒƒãƒã®ãŸã‚ã«å°‘ã—å¾…æ©Ÿ
                    import time
                    time.sleep(1)
                    st.rerun()
            else:
                # å‡¦ç†å®Œäº†
                st.session_state['batch_processing'] = False
                st.session_state['batch_processed_count'] = 0
                st.success("ğŸ‰ ãƒãƒƒãƒå‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                st.rerun()
        else:
            # å‡¦ç†å¯¾è±¡ãªã—
            st.session_state['batch_processing'] = False
            st.session_state['batch_processed_count'] = 0
            st.info("å‡¦ç†å¯¾è±¡ã®ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãŒã‚ã‚Šã¾ã›ã‚“")
            st.rerun()
    
    # ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãƒªã‚¹ãƒˆã®å¤‰æ›´ã‚’æ¤œçŸ¥
    if 'previous_accounts' not in st.session_state:
        st.session_state['previous_accounts'] = []
    
    previous_accounts = set(st.session_state['previous_accounts'])
    current_accounts = set(accounts)
    
    # æ–°ã—ãè¿½åŠ ã•ã‚ŒãŸã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’æ¤œå‡º
    new_accounts = current_accounts - previous_accounts
    
    # å‰Šé™¤ã•ã‚ŒãŸã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’æ¤œå‡º
    removed_accounts = previous_accounts - current_accounts
    
    # å‰Šé™¤ã•ã‚ŒãŸã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    for removed in removed_accounts:
        session_key = f"session_data_{removed}"
        if session_key in st.session_state:
            del st.session_state[session_key]
            logger.info(f"å‰Šé™¤ã•ã‚ŒãŸã‚¢ã‚«ã‚¦ãƒ³ãƒˆ @{removed} ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢")
    
    # ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãƒªã‚¹ãƒˆã‚’æ›´æ–°ï¼ˆåŒä¸€å‚ç…§ã‚’é¿ã‘ã‚‹ãŸã‚ã‚³ãƒ”ãƒ¼ã‚’ä¿å­˜ï¼‰
    st.session_state['previous_accounts'] = list(accounts)
    
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥çŠ¶æ³ã‚’æ›´æ–°
    st.session_state['account_status'] = check_cache_status(accounts)
    
    # all_dataã‚‚ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã§ç®¡ç†ï¼ˆå†å–å¾—ã‚’é˜²ãï¼‰
    all_data_key = "all_data_cache"
    current_accounts_key = tuple(sorted(accounts))  # ãƒãƒƒã‚·ãƒ¥å¯èƒ½ãªã‚­ãƒ¼ã«å¤‰æ›
    
    # ç¾åœ¨ã®ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãƒªã‚¹ãƒˆã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    if all_data_key in st.session_state and st.session_state.get('cached_accounts_key') == current_accounts_key:
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒã‚ã‚‹å ´åˆã¯å†åˆ©ç”¨
        all_data = st.session_state[all_data_key]
        logger.info(f"all_dataã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰èª­ã¿è¾¼ã¿: {len(all_data)}ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ")
    else:
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒãªã„ã€ã¾ãŸã¯ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãƒªã‚¹ãƒˆãŒå¤‰æ›´ã•ã‚ŒãŸå ´åˆã®ã¿å–å¾—
        logger.info("all_dataã‚’æ–°è¦å–å¾—")
        all_data = {}
        failed_accounts: List[str] = []
        for account in accounts:
            # ã¾ãšãƒ•ã‚¡ã‚¤ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ˜ç¤ºçš„ã«ç¢ºèªï¼ˆCLIâ†’UI é€£æºã‚’æœ€å„ªå…ˆï¼‰
            account_clean = account.lstrip('@')
            cache_key = f"posts_{account_clean}"
            session_key = f"session_data_{account_clean}"

            cached_data = load_cache(cache_key) if use_cache else None
            new_account = account in new_accounts

            posts: List[Dict] = []
            persona: Dict = {}
            use_cached = False

            if cached_data is not None:
                cached_posts = cached_data.get('posts', [])
                if has_generated_posts(cached_posts):
                    st.warning(
                        f"âš ï¸ @{account}: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ç”Ÿæˆãƒ‡ãƒ¼ã‚¿ãŒå«ã¾ã‚Œã¦ã„ã‚‹ãŸã‚å‰Šé™¤ã—å†å–å¾—ã—ã¾ã™ã€‚"
                    )
                    delete_cache(cache_key)
                    if session_key in st.session_state:
                        del st.session_state[session_key]
                    cached_data = None
                else:
                    if new_account:
                        st.info(f"ğŸ“¦ æ–°ã—ã„ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ: @{account} - ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å³æ™‚ãƒ­ãƒ¼ãƒ‰")
                    st.session_state[session_key] = cached_data
                    update_account_status(account_clean, 'cached_file')
                    posts = cached_posts
                    persona = cached_data.get('persona', {})
                    if ensure_quality_score(grok_api, persona, account_clean, x_api):
                        cached_data['persona'] = persona
                        st.session_state[session_key] = cached_data
                        cache_data(cache_key, cached_data)
                    use_cached = True

            should_force_refresh = new_account and not use_cached

            if not use_cached:
                if new_account and should_force_refresh:
                    st.info(f"ğŸ†• æ–°ã—ã„ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ: @{account} - æŠ•ç¨¿ã‚’å–å¾—ã—ã¾ã™")
                posts, persona = fetch_and_analyze_posts(
                    grok_api,
                    account,
                    use_cache,
                    x_api,
                    force_refresh=should_force_refresh
                )

            if posts and persona:
                all_data[account] = {
                    'posts': posts,
                    'persona': persona
                }
            else:
                failed_accounts.append(account)
                update_account_status(account_clean, 'unverified')
                # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¯å¤±æ•—æ™‚ã«ç ´æ£„ã—ã¦å†è©¦è¡Œã—ã‚„ã™ãã™ã‚‹
                if session_key in st.session_state:
                    del st.session_state[session_key]

        if failed_accounts:
            st.info(f"ğŸ”„ {len(failed_accounts)}ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®å†è©¦è¡Œä¸­...")
            for account in failed_accounts:
                account_clean = account.lstrip('@')
                session_key = f"session_data_{account_clean}"
                posts, persona = fetch_and_analyze_posts(
                    grok_api,
                    account,
                    use_cache=False,
                    x_api=x_api,
                    force_refresh=True
                )

                if posts and persona:
                    all_data[account] = {
                        'posts': posts,
                        'persona': persona
                    }
                    st.success(f"âœ… @{account}: å†è©¦è¡Œã§å–å¾—æˆåŠŸ")
                else:
                    st.warning(f"âš ï¸ @{account}: å†è©¦è¡Œå¾Œã‚‚å–å¾—å¤±æ•— - è­°è«–ã‹ã‚‰é™¤å¤–")
                    update_account_status(account_clean, 'unverified')
                    if session_key in st.session_state:
                        del st.session_state[session_key]

        # all_dataã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
        st.session_state[all_data_key] = all_data
        st.session_state['cached_accounts_key'] = tuple(sorted(all_data.keys()))
        logger.info(f"all_dataã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜: {len(all_data)}ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ")
    
    # ã‚¿ãƒ–ä½œæˆ
    tabs = st.tabs(["ğŸ¯ è­°è«–ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³", "ğŸ‘¤ ãƒšãƒ«ã‚½ãƒŠåˆ†æ", "ğŸ“Š æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿", "ğŸ“‹ ã‚¢ã‚«ã‚¦ãƒ³ãƒˆç®¡ç†"])
    
    # === ã‚¿ãƒ–1: è­°è«–ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆãƒãƒ£ãƒƒãƒˆé¢¨UI + ã‚¿ãƒ¼ãƒ³åˆ¶ï¼‰ ===
    with tabs[0]:
        st.header("ğŸ¯ è­°è«–ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
        
        if not all_data:
            st.warning("ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            return
        
        # DebateUIåˆæœŸåŒ–
        debate_ui = DebateUI()
        
        # ä¸Šéƒ¨ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«
        col1, col2, col3 = st.columns([3, 1, 1])
        
        with col1:
            # ãƒˆãƒ”ãƒƒã‚¯å…¥åŠ›
            topic = st.text_input(
                "ğŸ’¬ è­°è«–ãƒˆãƒ”ãƒƒã‚¯",
                value=st.session_state.get('debate_topic', 'AIã®å€«ç†çš„èª²é¡Œã«ã¤ã„ã¦'),
                placeholder="è­°è«–ã—ãŸã„ãƒˆãƒ”ãƒƒã‚¯ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
                autocomplete="off"
            )
            st.session_state['debate_topic'] = topic
        
        with col2:
            # æ–°ã—ã„è­°è«–ã‚’é–‹å§‹
            if st.button("ğŸ†• æ–°ã—ã„è­°è«–", use_container_width=True):
                debate_ui.clear_debate()
                if grok_api:
                    grok_api.clear_conversation_history()
                # ã‚¢ãƒã‚¿ãƒ¼å‰²ã‚Šå½“ã¦ã‚‚ã‚¯ãƒªã‚¢ï¼ˆå®Œå…¨ãƒªã‚»ãƒƒãƒˆï¼‰
                if 'account_avatars' in st.session_state:
                    st.session_state['account_avatars'] = {}
                st.success("è­°è«–ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸ")
                st.rerun()
        
        with col3:
            # ç¾åœ¨ã®ãƒ©ã‚¦ãƒ³ãƒ‰è¡¨ç¤º
            current_round = debate_ui.get_current_round()
            st.metric("ãƒ©ã‚¦ãƒ³ãƒ‰", current_round)
        
        st.markdown("---")
        
        # å‚åŠ è€…ãƒªã‚¹ãƒˆ
        debate_ui.render_participant_list(list(all_data.keys()))
        
        st.markdown("---")
        
        # è­°è«–ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³
        debate_ui.render_debate_timeline()
        
        st.markdown("---")
        
        # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒœã‚¿ãƒ³
        if current_round == 0:
            # åˆå›ãƒ©ã‚¦ãƒ³ãƒ‰: å…¨å“¡ã®æ„è¦‹ã‚’ç”Ÿæˆ
            if st.button("ğŸš€ è­°è«–ã‚’é–‹å§‹", type="primary", use_container_width=True):
                if not topic.strip():
                    st.error("ãƒˆãƒ”ãƒƒã‚¯ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
                else:
                    # é¡ä¼¼æ¤œç´¢ã®åˆæœŸåŒ–
                    with st.spinner("ğŸ” é¡ä¼¼æ¤œç´¢ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­..."):
                        searcher = SimilaritySearcher()
                    
                    # ãƒšãƒ«ã‚½ãƒŠãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼åˆæœŸåŒ–
                    persona_manager = PersonaManager()
                    
                    # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ©Ÿèƒ½ã®çŠ¶æ…‹ã‚’å–å¾—
                    use_history, use_web_search, _ = get_agent_settings()
                    
                    # å„ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®åˆå›æ„è¦‹ã‚’ç”Ÿæˆ
                    for account, data in all_data.items():
                        posts = data['posts']
                        persona = data['persona']
                        
                        if not posts or not persona:
                            st.warning(f"âš ï¸ @{account}: ãƒ‡ãƒ¼ã‚¿ä¸è¶³ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—")
                            continue
                        
                        # é–¢é€£æŠ•ç¨¿æ¤œç´¢
                        with st.spinner(f"ğŸ” @{account}ã®é–¢é€£æŠ•ç¨¿ã‚’æ¤œç´¢ä¸­..."):
                            relevant_posts = searcher.find_relevant_posts(topic, posts, top_k=TOP_K_RELEVANT_POSTS)
                        
                        # æ„è¦‹ç”Ÿæˆ
                        with st.spinner(f"âœï¸ @{account}ã®æ„è¦‹ã‚’ç”Ÿæˆä¸­..."):
                            opinion = grok_api.generate_debate_opinion(
                                topic, 
                                persona, 
                                relevant_posts,
                                use_history=use_history,
                                enable_live_search=use_web_search
                            )
                        
                        if opinion:
                            # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
                            debate_ui.add_message(
                                account=account,
                                name=persona.get('name', account),
                                content=opinion,
                                message_type="initial"
                            )
                    
                    # ä¼šè©±å±¥æ­´ã‚µãƒãƒªãƒ¼ã‚’æ›´æ–°
                    if use_history:
                        st.session_state['grok_history_summary'] = grok_api.get_conversation_summary()
                    
                    # ãƒ©ã‚¦ãƒ³ãƒ‰ã‚’é€²ã‚ã‚‹
                    debate_ui.increment_round()
                    st.success("âœ… åˆå›æ„è¦‹ã‚’ç”Ÿæˆã—ã¾ã—ãŸï¼")
                    st.rerun()
        
        else:
            # åè«–ãƒ©ã‚¦ãƒ³ãƒ‰: èª°ãŒèª°ã«åè«–ã™ã‚‹ã‹é¸æŠ
            st.subheader("ğŸ”„ æ¬¡ã®ãƒ©ã‚¦ãƒ³ãƒ‰ã‚’ç”Ÿæˆ")
            
            col1, col2 = st.columns(2)
            
            with col1:
                # åè«–ã™ã‚‹äººã‚’é¸æŠ
                replier = st.selectbox(
                    "åè«–ã™ã‚‹äºº",
                    options=list(all_data.keys()),
                    format_func=lambda x: f"@{x} ({all_data[x]['persona'].get('name', x)})"
                )
            
            with col2:
                # åè«–å¯¾è±¡ã‚’é¸æŠ
                other_accounts = [acc for acc in all_data.keys() if acc != replier]
                if other_accounts:
                    target = st.selectbox(
                        "åè«–å¯¾è±¡",
                        options=other_accounts,
                        format_func=lambda x: f"@{x} ({all_data[x]['persona'].get('name', x)})"
                    )
                else:
                    target = None
                    st.warning("åè«–å¯¾è±¡ãŒã„ã¾ã›ã‚“")
            
            col_action1, col_action2 = st.columns(2)
            
            with col_action1:
                # é¸æŠã—ãŸåè«–ã‚’ç”Ÿæˆ
                if target and st.button("ğŸ’¬ é¸æŠã—ãŸåè«–ã‚’ç”Ÿæˆ", type="primary", use_container_width=True):
                    # å¯¾è±¡ã®æœ€æ–°æ„è¦‹ã‚’å–å¾—
                    target_messages = [m for m in debate_ui.get_messages() if m.account == target]
                    if target_messages:
                        target_message = target_messages[-1]
                        
                        # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ©Ÿèƒ½ã®çŠ¶æ…‹ã‚’å–å¾—
                        use_history, use_web_search, _ = get_agent_settings()
                        
                        # ã“ã‚Œã¾ã§ã®æ–‡è„ˆã‚’æ§‹ç¯‰
                        previous_context = build_previous_context(debate_ui)
                        
                        # åè«–ç”Ÿæˆ
                        with st.spinner(f"âœï¸ @{replier}ã®åè«–ã‚’ç”Ÿæˆä¸­..."):
                            rebuttal = grok_api.generate_rebuttal(
                                topic=topic,
                                persona=all_data[replier]['persona'],
                                target_account=target,
                                target_opinion=target_message.content,
                                previous_context=previous_context,
                                use_history=use_history,
                                enable_live_search=use_web_search
                            )
                        
                        if rebuttal:
                            # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
                            debate_ui.add_message(
                                account=replier,
                                name=all_data[replier]['persona'].get('name', replier),
                                content=rebuttal,
                                reply_to=target,
                                message_type="rebuttal"
                            )
                            
                            # ä¼šè©±å±¥æ­´ã‚µãƒãƒªãƒ¼ã‚’æ›´æ–°
                            if use_history:
                                st.session_state['grok_history_summary'] = grok_api.get_conversation_summary()
                            
                            st.success(f"âœ… @{replier}ã®åè«–ã‚’ç”Ÿæˆã—ã¾ã—ãŸï¼")
                            st.rerun()
                        else:
                            st.error("åè«–ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
                    else:
                        st.error(f"@{target}ã®æ„è¦‹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            
            with col_action2:
                # å…¨å“¡ã«åè«–ã•ã›ã‚‹
                if st.button("ğŸ”„ å…¨å“¡ã®åè«–ã‚’ç”Ÿæˆ", use_container_width=True):
                    # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ©Ÿèƒ½ã®çŠ¶æ…‹ã‚’å–å¾—
                    use_history, use_web_search, _ = get_agent_settings()
                    
                    # å„ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãŒä»–ã®èª°ã‹ã«åè«–
                    accounts_list = list(all_data.keys())
                    for i, account in enumerate(accounts_list):
                        # åè«–å¯¾è±¡ã‚’é¸æŠï¼ˆæ¬¡ã®äººã€ã¾ãŸã¯æœ€åˆã®äººï¼‰
                        target_idx = (i + 1) % len(accounts_list)
                        target_account = accounts_list[target_idx]
                        
                        # å¯¾è±¡ã®æœ€æ–°æ„è¦‹ã‚’å–å¾—
                        target_messages = [m for m in debate_ui.get_messages() if m.account == target_account]
                        if not target_messages:
                            continue
                        
                        target_message = target_messages[-1]
                        
                        # ã“ã‚Œã¾ã§ã®æ–‡è„ˆã‚’æ§‹ç¯‰
                        previous_context = build_previous_context(debate_ui)
                        
                        # åè«–ç”Ÿæˆ
                        with st.spinner(f"âœï¸ @{account}ã®åè«–ã‚’ç”Ÿæˆä¸­..."):
                            rebuttal = grok_api.generate_rebuttal(
                                topic=topic,
                                persona=all_data[account]['persona'],
                                target_account=target_account,
                                target_opinion=target_message.content,
                                previous_context=previous_context,
                                use_history=use_history,
                                enable_live_search=use_web_search
                            )
                        
                        if rebuttal:
                            # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
                            debate_ui.add_message(
                                account=account,
                                name=all_data[account]['persona'].get('name', account),
                                content=rebuttal,
                                reply_to=target_account,
                                message_type="rebuttal"
                            )
                    
                    # ãƒ©ã‚¦ãƒ³ãƒ‰ã‚’é€²ã‚ã‚‹
                    debate_ui.increment_round()
                    
                    # ä¼šè©±å±¥æ­´ã‚µãƒãƒªãƒ¼ã‚’æ›´æ–°
                    if use_history:
                        st.session_state['grok_history_summary'] = grok_api.get_conversation_summary()
                    
                    st.success("âœ… å…¨å“¡ã®åè«–ã‚’ç”Ÿæˆã—ã¾ã—ãŸï¼")
                    st.rerun()
    
    # === ã‚¿ãƒ–2: ãƒšãƒ«ã‚½ãƒŠåˆ†æ ===
    with tabs[1]:
        st.header("ğŸ‘¤ ãƒšãƒ«ã‚½ãƒŠåˆ†æ")
        
        for account, data in all_data.items():
            persona = data['persona']
            posts = data['posts']
            
            if not persona:
                continue
            
            persona_manager = PersonaManager()
            full_persona = persona_manager.create_persona(account, posts, persona)
            
            # ãƒšãƒ«ã‚½ãƒŠã‚µãƒãƒªãƒ¼è¡¨ç¤º
            st.markdown(persona_manager.format_persona_summary(full_persona))
            st.markdown("---")
    
    # === ã‚¿ãƒ–3: æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿ ===
    with tabs[2]:
        st.header("ğŸ“Š æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿")
        
        for account, data in all_data.items():
            posts = data['posts']
            
            if not posts:
                continue
            
            st.subheader(f"@{account} ã®æŠ•ç¨¿ ({len(posts)}ä»¶)")
            
            # ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆãƒœã‚¿ãƒ³
            col1, col2 = st.columns([3, 1])
            with col2:
                json_data = json.dumps(posts, ensure_ascii=False, indent=2)
                st.download_button(
                    label="ğŸ“¥ JSONãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=json_data,
                    file_name=f"{account}_posts_{datetime.now().strftime('%Y%m%d')}.json",
                    mime="application/json"
                )
            
            # æŠ•ç¨¿ãƒªã‚¹ãƒˆè¡¨ç¤º
            for i, post in enumerate(posts[:10]):  # æœ€åˆã®10ä»¶
                with st.expander(f"æŠ•ç¨¿ {i+1} - {post.get('date', 'N/A')[:10]}"):
                    st.markdown(post['text'])
                    st.markdown(f"[ğŸ”— æŠ•ç¨¿ã‚’è¦‹ã‚‹]({post['link']})")
            
            if len(posts) > 10:
                st.info(f"æ®‹ã‚Š{len(posts) - 10}ä»¶ã®æŠ•ç¨¿ã¯éè¡¨ç¤º")
            
            st.markdown("---")
    
    # === ã‚¿ãƒ–4: ã‚¢ã‚«ã‚¦ãƒ³ãƒˆç®¡ç† ===
    with tabs[3]:
        st.header("ğŸ“‹ ã‚¢ã‚«ã‚¦ãƒ³ãƒˆç®¡ç†")
        
        if not all_data:
            st.warning("ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        else:
            # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚ªãƒ—ã‚·ãƒ§ãƒ³
            col1, col2, col3 = st.columns(3)
            
            with col1:
                status_filter = st.selectbox(
                    "ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã§ãƒ•ã‚£ãƒ«ã‚¿",
                    options=["å…¨ã¦", "ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ¸ˆã¿", "å–å¾—å¾…ã¡", "ã‚¨ãƒ©ãƒ¼"],
                    help="ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°"
                )
            
            with col2:
                search_term = st.text_input(
                    "ã‚¢ã‚«ã‚¦ãƒ³ãƒˆåã§æ¤œç´¢",
                    placeholder="ã‚¢ã‚«ã‚¦ãƒ³ãƒˆåã®ä¸€éƒ¨ã‚’å…¥åŠ›",
                    help="ã‚¢ã‚«ã‚¦ãƒ³ãƒˆåã®ä¸€éƒ¨ã§æ¤œç´¢",
                    autocomplete="off"
                )
            
            with col3:
                sort_option = st.selectbox(
                    "ä¸¦ã³é †",
                    options=["ã‚¢ã‚«ã‚¦ãƒ³ãƒˆå", "ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹", "æŠ•ç¨¿æ•°"],
                    help="è¡¨ç¤ºé †åºã‚’é¸æŠ"
                )
            
            # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã¨ã‚½ãƒ¼ãƒˆ
            filtered_accounts = []
            for account, data in all_data.items():
                # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒ•ã‚£ãƒ«ã‚¿
                account_status = st.session_state.get('account_status', {}).get(account, 'pending')
                if status_filter == "å…¨ã¦":
                    pass
                elif status_filter == "ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ¸ˆã¿" and account_status not in ['cached_session', 'cached_file']:
                    continue
                elif status_filter == "å–å¾—å¾…ã¡" and account_status != 'pending':
                    continue
                elif status_filter == "ã‚¨ãƒ©ãƒ¼" and account_status != 'error':
                    continue
                
                # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹å–å¾—ï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³å„ªå…ˆ â†’ ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰
                sess_key = f"session_data_{account}"
                source_val = None
                if sess_key in st.session_state:
                    source_val = st.session_state[sess_key].get('source')
                if not source_val:
                    cached_obj = load_cache(f"posts_{account}")
                    if cached_obj:
                        source_val = cached_obj.get('source')
                # ã‚«ãƒ†ã‚´ãƒªãƒãƒƒãƒ”ãƒ³ã‚°
                if source_val == 'twitter':
                    source_cat = 'Twitter'
                elif source_val == 'web_search':
                    source_cat = 'Web'
                elif source_val == 'generated':
                    source_cat = 'Sample'
                elif source_val == 'grok_keyword':
                    source_cat = 'Keyword'
                elif source_val == 'grok_random':
                    source_cat = 'Random'
                elif source_val == 'diversity_hybrid':
                    source_cat = 'Diversity'
                else:
                    source_cat = 'Unknown'
                
                # ã‚½ãƒ¼ã‚¹ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼‰
                sf = st.session_state.get('source_filter', ["å…¨ã¦"]) or ["å…¨ã¦"]
                if "å…¨ã¦" not in sf:
                    if source_cat not in sf:
                        continue
                
                # æ¤œç´¢ãƒ•ã‚£ãƒ«ã‚¿
                if search_term and search_term.lower() not in account.lower():
                    continue
                
                # æœªå–å¾—ã®ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã¯ discovery æƒ…å ±ã‚’è£œåŠ©è¡¨ç¤º
                if source_cat == 'Unknown':
                    disc = st.session_state.get('discovered_source', {}).get(account)
                    if disc == 'grok_keyword':
                        source_cat = 'Keyword'
                    elif disc == 'grok_random':
                        source_cat = 'Random'
                    elif disc == 'diversity_hybrid':
                        source_cat = 'Diversity'
                
                filtered_accounts.append((account, data, account_status, source_cat))
            
            # ã‚½ãƒ¼ãƒˆ
            if sort_option == "ã‚¢ã‚«ã‚¦ãƒ³ãƒˆå":
                filtered_accounts.sort(key=lambda x: x[0])
            elif sort_option == "ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹":
                filtered_accounts.sort(key=lambda x: x[2])
            elif sort_option == "æŠ•ç¨¿æ•°":
                filtered_accounts.sort(key=lambda x: len(x[1].get('posts', [])), reverse=True)
            
            # çµæœè¡¨ç¤º
            st.markdown(f"**è¡¨ç¤ºä¸­: {len(filtered_accounts)} / {len(all_data)} ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ**")
            
            if filtered_accounts:
                # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ å½¢å¼ã§è¡¨ç¤º
                display_data = []
                for account, data, status, source_cat in filtered_accounts:
                    posts = data.get('posts', [])
                    persona = data.get('persona', {})
                    
                    # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤º
                    status_display = {
                        'cached_session': 'âœ… ã‚»ãƒƒã‚·ãƒ§ãƒ³',
                        'cached_file': 'ğŸ“¦ ãƒ•ã‚¡ã‚¤ãƒ«',
                        'pending': 'â³ å¾…æ©Ÿä¸­',
                        'error': 'âŒ ã‚¨ãƒ©ãƒ¼'
                    }.get(status, 'â“ ä¸æ˜')
                    
                    # ã‚½ãƒ¼ã‚¹ãƒãƒƒã‚¸
                    if source_cat == 'Twitter':
                        source_display = 'âœ… Twitter'
                    elif source_cat == 'Web':
                        source_display = 'ğŸŒ Web'
                    elif source_cat == 'Sample':
                        source_display = 'ğŸ“ Sample'
                    elif source_cat == 'Keyword':
                        source_display = 'ğŸ” Keyword'
                    elif source_cat == 'Random':
                        source_display = 'ğŸ² Random'
                    else:
                        source_display = 'â“ Unknown'
                    
                    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ—¥æ™‚ã‚’å–å¾—
                    cache_time = "ä¸æ˜"
                    if status in ['cached_session', 'cached_file']:
                        fetched_at = None
                        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ã‚ã‚Œã°å„ªå…ˆ
                        session_key = f"session_data_{account}"
                        if session_key in st.session_state:
                            fetched_at = st.session_state[session_key].get('fetched_at')
                        if not fetched_at:
                            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å–å¾—
                            cached = load_cache(f"posts_{account}")
                            if cached:
                                fetched_at = cached.get('fetched_at')
                        if fetched_at:
                            try:
                                cache_time = datetime.fromisoformat(fetched_at).strftime("%Y-%m-%d %H:%M")
                            except Exception:
                                cache_time = fetched_at
                    
                    display_data.append({
                        "ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ": f"@{account}",
                        "ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹": status_display,
                        "ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹": source_display,
                        "æŠ•ç¨¿æ•°": len(posts),
                        "ãƒšãƒ«ã‚½ãƒŠå": persona.get('name', account),
                        "ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ—¥æ™‚": cache_time
                    })
                
                # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ è¡¨ç¤º
                df = pd.DataFrame(display_data)
                st.dataframe(
                    df,
                    width='stretch',
                    hide_index=True,
                    column_config={
                        "ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ": st.column_config.TextColumn("ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ", width="medium"),
                        "ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹": st.column_config.TextColumn("ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹", width="small"),
                        "ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹": st.column_config.TextColumn("ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹", width="small"),
                        "æŠ•ç¨¿æ•°": st.column_config.NumberColumn("æŠ•ç¨¿æ•°", width="small"),
                        "ãƒšãƒ«ã‚½ãƒŠå": st.column_config.TextColumn("ãƒšãƒ«ã‚½ãƒŠå", width="medium"),
                        "ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ—¥æ™‚": st.column_config.TextColumn("ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ—¥æ™‚", width="small")
                    }
                )
                
                # ä¸€æ‹¬æ“ä½œãƒœã‚¿ãƒ³
                st.markdown("---")
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    if st.button("ğŸ”„ é¸æŠã—ãŸã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’å†å–å¾—", use_container_width=True):
                        # ãƒ•ã‚£ãƒ«ã‚¿ã•ã‚ŒãŸã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’å†å–å¾—
                        for account, _, _, _ in filtered_accounts:
                            session_key = f"session_data_{account}"
                            if session_key in st.session_state:
                                del st.session_state[session_key]
                        if 'all_data_cache' in st.session_state:
                            del st.session_state['all_data_cache']
                        if 'cached_accounts_key' in st.session_state:
                            del st.session_state['cached_accounts_key']
                        st.success("é¸æŠã—ãŸã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®å†å–å¾—ã‚’é–‹å§‹ã—ã¾ã™")
                        st.rerun()
                
                with col2:
                    if st.button("ğŸ“¥ ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ", use_container_width=True):
                        # å…¨ãƒ‡ãƒ¼ã‚¿ã‚’JSONã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
                        export_data = {}
                        for account, data, _, _ in filtered_accounts:
                            export_data[account] = {
                                'posts': data.get('posts', []),
                                'persona': data.get('persona', {})
                            }
                        
                        json_data = json.dumps(export_data, ensure_ascii=False, indent=2)
                        st.download_button(
                            label="ğŸ“¥ JSONãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                            data=json_data,
                            file_name=f"persona_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                            mime="application/json"
                        )
                
                with col3:
                    if st.button("ğŸ—‘ï¸ é¸æŠã—ãŸã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’å‰Šé™¤", use_container_width=True):
                        # ãƒ•ã‚£ãƒ«ã‚¿ã•ã‚ŒãŸã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’å‰Šé™¤
                        for account, _, _, _ in filtered_accounts:
                            if account in st.session_state['accounts_list']:
                                st.session_state['accounts_list'].remove(account)
                            session_key = f"session_data_{account}"
                            if session_key in st.session_state:
                                del st.session_state[session_key]
                        if 'all_data_cache' in st.session_state:
                            del st.session_state['all_data_cache']
                        if 'cached_accounts_key' in st.session_state:
                            del st.session_state['cached_accounts_key']
                        st.success("é¸æŠã—ãŸã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
                        st.rerun()
            else:
                st.info("ãƒ•ã‚£ãƒ«ã‚¿æ¡ä»¶ã«ä¸€è‡´ã™ã‚‹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãŒã‚ã‚Šã¾ã›ã‚“")
    
    # ãƒ•ãƒƒã‚¿ãƒ¼
    st.markdown("---")
    st.markdown("**Persona Debate Simulator** | Powered by Grok API & Streamlit")


if __name__ == "__main__":
    main()
